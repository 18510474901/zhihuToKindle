


怎样用Python设计一个爬虫模拟登陆知乎？ - 爬虫（计算机网络） - 知乎






--------------------Link http://www.zhihu.com/question/29925879 ----------------------





--------------------Detail----------------------


写了个关于模拟登录常见网站的小项目，GitHub - xchaoinfo/fuck-login: 模拟登录一些知名的网站，为了方便爬取需要登录的网站其中包括知乎 百度 新浪微博 126 邮箱 web微信等，考虑了 Py2 Py3 版本兼容 以及验证码的问题，欢迎大家来围观 pull request既然是问的模拟登录知乎，那我还是贴出来代码吧。虽然你们可以直接到 github 上看。经过多次修改，代码的兼容和健壮性都有了很大的改进。Py2 Py3 兼容，代码符合 PEP 8 规范，如果你有更好的改进方案，欢迎 Pull Request#!/usr/bin/env python3
# -*- coding: utf-8 -*-
'''
Required
- requests (必须)
- pillow (可选)
Info
- author : "xchaoinfo"
- email  : "xchaoinfo@qq.com"
- date   : "2016.2.4"
Update
- name   : "wangmengcn"
- email  : "eclipse_sv@163.com"
- date   : "2016.4.21"
'''
import requests
try:
    import cookielib
except:
    import http.cookiejar as cookielib
import re
import time
import os.path
try:
    from PIL import Image
except:
    pass


# 构造 Request headers
agent = 'Mozilla/5.0 (Windows NT 5.1; rv:33.0) Gecko/20100101 Firefox/33.0'
headers = {
    'User-Agent': agent
}

# 使用登录cookie信息
session = requests.session()
session.cookies = cookielib.LWPCookieJar(filename='cookies')
try:
    session.cookies.load(ignore_discard=True)
except:
    print("Cookie 未能加载")


def get_xsrf():
    '''_xsrf 是一个动态变化的参数'''
    index_url = 'http://www.zhihu.com'
    # 获取登录时需要用到的_xsrf
    index_page = session.get(index_url, headers=headers)
    html = index_page.text
    pattern = r'name="_xsrf" value="(.*?)"'
    # 这里的_xsrf 返回的是一个list
    _xsrf = re.findall(pattern, html)
    return _xsrf[0]


# 获取验证码
def get_captcha():
    t = str(int(time.time()*1000))
    captcha_url = 'http://www.zhihu.com/captcha.gif?r=' + t + "&type=login"
    r = session.get(captcha_url, headers=headers)
    with open('captcha.jpg', 'wb') as f:
        f.write(r.content)
        f.close()
    # 用pillow 的 Image 显示验证码
    # 如果没有安装 pillow 到源代码所在的目录去找到验证码然后手动输入
    try:
        im = Image.open('captcha.jpg')
        im.show()
        im.close()
    except:
        print(u'请到 %s 目录找到captcha.jpg 手动输入' % os.path.abspath('captcha.jpg'))
    captcha = input("please input the captcha\n>")
    return captcha


def isLogin():
    # 通过查看用户个人信息来判断是否已经登录
    url = "https://www.zhihu.com/settings/profile"
    login_code = session.get(url,allow_redirects=False).status_code
    if int(x=login_code) == 200:
        return True
    else:
        return False



def login(secret, account):
    # 通过输入的用户名判断是否是手机号
    if re.match(r"^1\d{10}$", account):
        print("手机号登录 \n")
        post_url = 'http://www.zhihu.com/login/phone_num'
        postdata = {
            '_xsrf': get_xsrf(),
            'password': secret,
            'remember_me': 'true',
            'phone_num': account,
        }
    else:
        print("邮箱登录 \n")
        post_url = 'http://www.zhihu.com/login/email'
        postdata = {
            '_xsrf': get_xsrf(),
            'password': secret,
            'remember_me': 'true',
            'email': account,
        }
    try:
        # 不需要验证码直接登录成功
        login_page = session.post(post_url, data=postdata, headers=headers)
        login_code = login_page.text
        print(login_page.status)
        print(login_code)
    except:
        # 需要输入验证码后才能登录成功
        postdata["captcha"] = get_captcha()
        login_page = session.post(post_url, data=postdata, headers=headers)
        login_code = eval(login_page.text)
        print(login_code['msg'])
    session.cookies.save()

try:
    input = raw_input
except:
    pass


if __name__ == '__main__':
    if isLogin():
        print('您已经登录')
    else:
        account = input('请输入你的用户名\n>  ')
        secret = input("请输入你的密码\n>  ")
        login(secret, account)



-------------------------answer 0 via  -------------------------


写了个关于模拟登录常见网站的小项目，GitHub - xchaoinfo/fuck-login: 模拟登录一些知名的网站，为了方便爬取需要登录的网站其中包括知乎 百度 新浪微博 126 邮箱 web微信等，考虑了 Py2 Py3 版本兼容 以及验证码的问题，欢迎大家来围观 pull request既然是问的模拟登录知乎，那我还是贴出来代码吧。虽然你们可以直接到 github 上看。经过多次修改，代码的兼容和健壮性都有了很大的改进。Py2 Py3 兼容，代码符合 PEP 8 规范，如果你有更好的改进方案，欢迎 Pull Request#!/usr/bin/env python3
# -*- coding: utf-8 -*-
'''
Required
- requests (必须)
- pillow (可选)
Info
- author : "xchaoinfo"
- email  : "xchaoinfo@qq.com"
- date   : "2016.2.4"
Update
- name   : "wangmengcn"
- email  : "eclipse_sv@163.com"
- date   : "2016.4.21"
'''
import requests
try:
    import cookielib
except:
    import http.cookiejar as cookielib
import re
import time
import os.path
try:
    from PIL import Image
except:
    pass


# 构造 Request headers
agent = 'Mozilla/5.0 (Windows NT 5.1; rv:33.0) Gecko/20100101 Firefox/33.0'
headers = {
    'User-Agent': agent
}

# 使用登录cookie信息
session = requests.session()
session.cookies = cookielib.LWPCookieJar(filename='cookies')
try:
    session.cookies.load(ignore_discard=True)
except:
    print("Cookie 未能加载")


def get_xsrf():
    '''_xsrf 是一个动态变化的参数'''
    index_url = 'http://www.zhihu.com'
    # 获取登录时需要用到的_xsrf
    index_page = session.get(index_url, headers=headers)
    html = index_page.text
    pattern = r'name="_xsrf" value="(.*?)"'
    # 这里的_xsrf 返回的是一个list
    _xsrf = re.findall(pattern, html)
    return _xsrf[0]


# 获取验证码
def get_captcha():
    t = str(int(time.time()*1000))
    captcha_url = 'http://www.zhihu.com/captcha.gif?r=' + t + "&type=login"
    r = session.get(captcha_url, headers=headers)
    with open('captcha.jpg', 'wb') as f:
        f.write(r.content)
        f.close()
    # 用pillow 的 Image 显示验证码
    # 如果没有安装 pillow 到源代码所在的目录去找到验证码然后手动输入
    try:
        im = Image.open('captcha.jpg')
        im.show()
        im.close()
    except:
        print(u'请到 %s 目录找到captcha.jpg 手动输入' % os.path.abspath('captcha.jpg'))
    captcha = input("please input the captcha\n>")
    return captcha


def isLogin():
    # 通过查看用户个人信息来判断是否已经登录
    url = "https://www.zhihu.com/settings/profile"
    login_code = session.get(url,allow_redirects=False).status_code
    if int(x=login_code) == 200:
        return True
    else:
        return False



def login(secret, account):
    # 通过输入的用户名判断是否是手机号
    if re.match(r"^1\d{10}$", account):
        print("手机号登录 \n")
        post_url = 'http://www.zhihu.com/login/phone_num'
        postdata = {
            '_xsrf': get_xsrf(),
            'password': secret,
            'remember_me': 'true',
            'phone_num': account,
        }
    else:
        print("邮箱登录 \n")
        post_url = 'http://www.zhihu.com/login/email'
        postdata = {
            '_xsrf': get_xsrf(),
            'password': secret,
            'remember_me': 'true',
            'email': account,
        }
    try:
        # 不需要验证码直接登录成功
        login_page = session.post(post_url, data=postdata, headers=headers)
        login_code = login_page.text
        print(login_page.status)
        print(login_code)
    except:
        # 需要输入验证码后才能登录成功
        postdata["captcha"] = get_captcha()
        login_page = session.post(post_url, data=postdata, headers=headers)
        login_code = eval(login_page.text)
        print(login_code['msg'])
    session.cookies.save()

try:
    input = raw_input
except:
    pass


if __name__ == '__main__':
    if isLogin():
        print('您已经登录')
    else:
        account = input('请输入你的用户名\n>  ')
        secret = input("请输入你的密码\n>  ")
        login(secret, account)



-------------------------answer 1 via  -------------------------


登录很简单，其实上面很多答案的很多内容都是可以去掉的。简化到最后奉上以下代码。(是手机号码登录的，想要邮箱的话改一下url和参数就可以了)#encoding=utf8
import cookielib
import urllib2
import urllib

url_start = r'https://www.zhihu.com/topic/19556498/questions?page='
cj = cookielib.CookieJar()
opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cj))
opener.addheaders = [('User-agent','Mozilla/5.0 (X11; Linux x86_64; rv:38.0) Gecko/20100101 Firefox/38.0 Iceweasel/38.3.0')]

def login():
    username = ''
    password = ''
    cap_url = 'https://www.zhihu.com/captcha.gif?r=1466595391805&type=login'
    cap_content = urllib2.urlopen(cap_url).read()
    cap_file = open('/root/Desktop/cap.gif','wb')
    cap_file.write(cap_content)
    cap_file.close()
    captcha = raw_input('capture:')
    url = 'https://www.zhihu.com/login/phone_num'
    data = urllib.urlencode({"phone_num":username,"password":password,"captcha":captcha})
    print urllib2.urlopen(url,data).read()
    
if __name__=="__main__":
    login()



-------------------------answer 2 via  -------------------------


抓包发现使用手机号登陆时，用户名的key是phone_num。登陆网址是：http://www.zhihu.com/login/phone_num
楼上都是Python 2，我放个Python 3的，用法见注释import requests
import time
import json
import os
import re
import sys
import subprocess
from bs4 import BeautifulSoup as BS


class ZhiHuClient(object):

    """连接知乎的工具类，维护一个Session
    2015.11.11

    用法：

    client = ZhiHuClient()

    # 第一次使用时需要调用此方法登录一次，生成cookie文件
    # 以后可以跳过这一步
    client.login("username", "password")   

    # 用这个session进行其他网络操作，详见requests库
    session = client.getSession()
    """

    # 网址参数是账号类型
    TYPE_PHONE_NUM = "phone_num"
    TYPE_EMAIL = "email"
    loginURL = r"http://www.zhihu.com/login/{0}"
    homeURL = r"http://www.zhihu.com"
    captchaURL = r"http://www.zhihu.com/captcha.gif"

    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2490.86 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        "Accept-Encoding": "gzip, deflate",
        "Host": "www.zhihu.com",
        "Upgrade-Insecure-Requests": "1",
    }

    captchaFile = os.path.join(sys.path[0], "captcha.gif")
    cookieFile = os.path.join(sys.path[0], "cookie")

    def __init__(self):
        os.chdir(sys.path[0])  # 设置脚本所在目录为当前工作目录

        self.__session = requests.Session()
        self.__session.headers = self.headers  # 用self调用类变量是防止将来类改名
        # 若已经有 cookie 则直接登录
        self.__cookie = self.__loadCookie()
        if self.__cookie:
            print("检测到cookie文件，直接使用cookie登录")
            self.__session.cookies.update(self.__cookie)
            soup = BS(self.open(r"http://www.zhihu.com/").text, "html.parser")
            print("已登陆账号： %s" % soup.find("span", class_="name").getText())
        else:
            print("没有找到cookie文件，请调用login方法登录一次！")

    # 登录
    def login(self, username, password):
        """
        验证码错误返回：
        {'errcode': 1991829, 'r': 1, 'data': {'captcha': '请提交正确的验证码 :('}, 'msg': '请提交正确的验证码 :('}
        登录成功返回：
        {'r': 0, 'msg': '登陆成功'}
        """
        self.__username = username
        self.__password = password
        self.__loginURL = self.loginURL.format(self.__getUsernameType())
        # 随便开个网页，获取登陆所需的_xsrf
        html = self.open(self.homeURL).text
        soup = BS(html, "html.parser") 
        _xsrf = soup.find("input", {"name": "_xsrf"})["value"]
        # 下载验证码图片
        while True:
            captcha = self.open(self.captchaURL).content
            with open(self.captchaFile, "wb") as output:
                output.write(captcha)
            # 人眼识别
            print("=" * 50)
            print("已打开验证码图片，请识别！")
            subprocess.call(self.captchaFile, shell=True)
            captcha = input("请输入验证码：")
            os.remove(self.captchaFile)
            # 发送POST请求
            data = {
                "_xsrf": _xsrf,
                "password": self.__password,
                "remember_me": "true",
                self.__getUsernameType(): self.__username,
                "captcha": captcha
            }
            res = self.__session.post(self.__loginURL, data=data)
            print("=" * 50)
            # print(res.text) # 输出脚本信息，调试用
            if res.json()["r"] == 0:
                print("登录成功")
                self.__saveCookie()
                break
            else:
                print("登录失败")
                print("错误信息 --->", res.json()["msg"])

    def __getUsernameType(self):
        """判断用户名类型
        经测试，网页的判断规则是纯数字为phone_num，其他为email
        """
        if self.__username.isdigit():
            return self.TYPE_PHONE_NUM
        return self.TYPE_EMAIL

    def __saveCookie(self):
        """cookies 序列化到文件
        即把dict对象转化成字符串保存
        """
        with open(self.cookieFile, "w") as output:
            cookies = self.__session.cookies.get_dict()
            json.dump(cookies, output)
            print("=" * 50)
            print("已在同目录下生成cookie文件：", self.cookieFile)

    def __loadCookie(self):
        """读取cookie文件，返回反序列化后的dict对象，没有则返回None"""
        if os.path.exists(self.cookieFile):
            print("=" * 50)
            with open(self.cookieFile, "r") as f:
                cookie = json.load(f)
                return cookie
        return None

    def open(self, url, delay=0, timeout=10):
        """打开网页，返回Response对象"""
        if delay:
            time.sleep(delay)
        return self.__session.get(url, timeout=timeout)

    def getSession(self):
        return self.__session

if __name__ == '__main__':
    client = ZhiHuClient()

    # 第一次使用时需要调用此方法登录一次，生成cookie文件
    # 以后可以跳过这一步
    # client.login("username", "password")   

    # 用这个session进行其他网络操作，详见requests库
    session = client.getSession()



-------------------------answer 3 via  -------------------------


lining0806/ZhihuSpider · GitHub


-------------------------answer 4 via  -------------------------


最近写了个python模拟登陆知乎的blog，有我的分析过程，分享给题主，题主可以参考下：http://www.cnblogs.com/ly941122/p/5401950.html


-------------------------answer 5 via  -------------------------


知乎现在登录貌似每次都会有密码了，修改如下：import requests
from xtls.util import BeautifulSoup

INDEX_URL = 'http://www.zhihu.com'
LOGIN_URL = 'http://www.zhihu.com/login/email'
CAPTCHA_URL = 'http://www.zhihu.com/captcha.gif?r='

def gen_time_stamp():
    return str(int(time.time())) + '%03d' % random.randint(0, 999)

def login(username, password, oncaptcha):
    session = requests.session()

    _xsrf = BeautifulSoup(session.get(INDEX_URL).content).find('input', attrs={'name': '_xsrf'})['value']
    data = {
        '_xsrf': _xsrf,
        'email': username,
        'password': password,
        'remember_me': 'true',
        'captcha': oncaptcha(session.get(CAPTCHA_URL + gen_time_stamp()).content)
    }
    resp = session.post(LOGIN_URL, data)
    if 2 != resp.status_code / 100 or u"登陆成功" not in resp.content:
        raise Exception('captcha error.')
    return session
其中，oncaptcha为一个回调函数（需要自己实现的），接受的参数为验证码的二进制内容，返回的为验证码内容。P.S.你可以自己做识别验证码，或者手动输入，其中最简单的oncaptcha为：def oncaptcha(data):
    with open('captcha file save path', 'wb') as fp:
        fp.write(data)
    return raw_input('captcha : ')



-------------------------answer 6 via  -------------------------


初学爬虫，贴上代码记录一下Python2.7.8/WINDOWS/requesrts、lxml库# -*- coding:utf-8 -*-
import requests
from lxml import etree

url = 'http://www.zhihu.com'
headers = {
        'Referer':'http://www.zhihu.com/',
        'User-Agent': 'Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.99 Safari/537.36'
}
xsrf = etree.HTML(requests.get(url, headers = headers).content).xpath('//input[@name="_xsrf"]/@value')[0]

data = {
        '_xsrf': xsrf,
        'email': 'xxxxxx',
        'password': 'xxxxxx',
        'remember_me': 'true'
}

# captcha_url = 'http://www.zhihu.com/captcha.gif'
# captcha = requests.get(captcha_url, stream=True)
# print captcha
# f = open('captcha.gif', 'wb')
# for line in captcha.iter_content(10):
#         f.write(line)
# f.close()
# print u'输入验证码:'
# captcha_str = raw_input()
# data['captcha'] = captcha_str

loginurl = url + '/login/email'
html = requests.post(loginurl, data = data, headers = headers)
cookies = html.cookies

url1 = 'https://www.zhihu.com/question/22591304/followers'
#这是通过fiddler获取的cookies
# cookies = {'Cookies':'xxxxxx'}
html = requests.get(url1,cookies=cookies,headers=headers).content
zhihu = etree.HTML(html)
content = zhihu.xpath('//a[@class="zg-link"]')
for each in content:
    text = each.xpath('string(.)')
    print text
------------------------------------------------------------没有泄露个人信息吧。。。不小心把账号密码贴出来了。。。


-------------------------answer 7 via  -------------------------


可以用 selenium 自动化浏览器 不过会比单纯的爬虫慢 http://www.seleniumhq.org


-------------------------answer 8 via  -------------------------


如果只是登录成功。这个代码段也可以。
import urllib
import urllib2

url = "http://www.zhihu.com/login/email"
user_agent = "Chrome/49.0.2623.87"
refer = "http://www.zhihu.com/"

values = {
"email" : "XXX@qq.com",
"password" : "XXX"
}

headers = {
"User-agent" : user_agent,
"Referer" : refer
}

data = urllib.urlencode(values)
request = urllib2.Request(url, data, headers)
response = urllib2.urlopen(request)
page = response.read()

print page



-------------------------answer 9 via  -------------------------


可以用Selenium控制浏览器来登录。利用Selenium来实现知乎和Bilibili的登录有一个演示视频可以看看
